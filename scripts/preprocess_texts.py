import os
import csv
#import re
from gutenbergdammit.ziputils import searchandretrieve

# This version uses the corpus and functions from 'Gutenberg, dammit'
# https://github.com/aparrish/gutenberg-dammit?tab=readme-ov-file

# Get absolute paths relative to this script's location
BASE_DIR = os.path.join(os.getenv('HOME'), 'argument')
RAW = os.path.join(BASE_DIR, "data","raw", "gutenberg-dammit-files-v002.zip")
PROCESSED_DIR = os.path.join(BASE_DIR, "data", "processed")
OUTPUT_CSV = os.path.join(PROCESSED_DIR, "passages.csv")

# Ensure processed directory exists
os.makedirs(PROCESSED_DIR, exist_ok=True)

# arbitrary list (yes, generated by the stupid junkbot)
# TODO - find a better list
PHILOSOPHERS = [
    "Thales",
    "Anaximander",
    "Anaximenes",
    "Pythagoras",
    "Heraclitus",
    "Parmenides",
    "Zeno",
    "Empedocles",
    "Anaxagoras",
    "Democritus",
    "Protagoras",
    "Gorgias",
    "Socrates",
    "Plato",
    "Aristotle",
    "Epicurus",
    "Chrysippus",
    "Pyrrho",
    "Carneades",
    "Cicero",
    "Lucretius",
    "Seneca",
    "Epictetus",
    "Aurelius",
    "Plotinus",
    "Porphyry",
    "Iamblichus",
    "Proclus",
    "Saint Augustine",
    "Boethius",
    "Eriugena",
    "Anselm",
    #"Abelard",
    #"Hildegard",
    "Aquinas",
    #"Bonaventure",
    #"Albertus",
    "Duns Scotus",
    "Ockham",
    #"Cusa",
    "Montaigne",
    "Montesquieu",
    "Bruno",
    "Francis Bacon",
    "Descartes",
    "Thomas Hobbes",
    "Gassendi",
    "Mersenne",
    "Arnauld",
    "Blaise Pascal",
    "Spinoza",
    "Malebranche",
    "John Locke",
    "Pufendorf",
    "Grotius",
    "Richard Cumberland",
    "Barbeyrac",
    "SuÃ¡rez",
    "Vitoria",
    "Machiavelli",
    "Bernard Mandeville",
    "Edmund Burke",
    "Johann Eberhard",
    "Samuel Clarke",
    "Cudworth",
    "Thomas More",
    "Leibniz",
    "Christian Wolff",
    "George Berkeley",
    "David Hume",
    "Francis Hutcheson",
    "Adam Smith",
    "Condillac",
    "Rousseau",
    "Diderot",
    "DAlembert",
    "Benjamin Constant",
    "James Harrington",
    #"Reid",
    "Beattie",
    "Hamann",
    "Moses Mendelssohn",
    "Kant",
    "Reinhold",
    "Fichte",
    "Schelling",
    "Hegel",
    "Schleiermacher",
    "Schopenhauer",
    #"Herbart",
    "Comte",
    "John Stuart Mill",
    "Bentham",
    "Feuerbach",
    "Karl Marx",
    "Kierkegaard",
    "Nietzsche",
    #"Franz Brentano",
    #"Bolzano",
    #"Lotze",
    #"Peirce",
    #"James",
    #"Frege"
]

def split_into_passages(text_lines):
    # split into passages
    # dialogues look very different than other texts
    # find passages that are likely text and long enough to be meaningful.
    # TODO - it'd be nice to remove translator, intro, meta-text

    passages = []
    buffer = []
    for line in text_lines.splitlines():
        if line == "":
            # if at line break with text in buffer:
            if buffer:
                buffer_string = " ".join(buffer).strip()

                # if we hit "" and there's no punctuation, it's probably not relevant.
                if ('.' in buffer_string) or ('?' in buffer_string) or ('!' in buffer_string):

                    # if text in buffer long enough to be meaningful, add as passage
                    if len(buffer_string) >= 100:
                            passages.append(buffer_string)

                    buffer = []
        else:
            buffer.append(line.strip())
    # ignore last bit of text
    #if buffer:
    #    buffer_string = " ".join(buffer).strip()
    #    if (('.' in buffer_string) or ('?' in buffer_string) or ('!' in buffer_string)) and  len(buffer_string) >= 100:
    #        passages.append(buffer_string)

    return passages

def main():
    # Note to self: subject:philosophy gives us a lot (~100),
    # but not everything I want
    # eg (missing Rousseau, Leibniz, some Kant, etc.)
    # for info, text in searchandretrieve(RAW, {'Subject': 'Philosophy'}):

    data = []
    file_id = 1

    for name in PHILOSOPHERS:
        for info, text in searchandretrieve(RAW, {'Author': name}):

            # check for multi-language texts. Some seem to be english +
            # eg "Cicero: Letters to Atticus, Volume III (of 3)" english and latin
            # unfortunately, its listed as just english, but contains latin too
            if info['Language'][0] != 'English' or len(info['Language'])>1:continue
            if info['Author'][0] == 'George Adam Smith':continue
            if info['Author'][0] == 'William John Locke':continue
            if 'Arguments of Celsus, Porphyry, and' in info['Title'][0]:continue

            # for works with more than 1 author, try to find the one that matched listed
            i=0
            for x,a in enumerate(info['Author']):
                if name in a:i=x

            author = name
            # TODO() - I meant to add author_full to output
            author_full = info['Author'][i]

            # year is sometimes missing. Fill in manually
            year_map = {
                "Plotinus": 204,
                "Porphyry": 234,
                "Bentham": 1748,
                "Seneca": -4
            }
            year = info['Author Birth'][i]
            if year is None and name in year_map:
                year = year_map[name]

            title = info['Title'][0]

            # Check for Missing
            if (author_full is None or year is None or title is None):
                print(f"MISSING: author:{author_full},year:{year},title:{title}")

            # TODO() - store per text info  in a csv
            print(f"{name},{info['Author'][i]},{info['Title'][0]}, {info['Author Birth'][i]}, {info['Language'][0]},{len(text)}")
            passages = split_into_passages(text)

            for idx, passage in enumerate(passages):
                data.append({
                    "id": f"{file_id}_{idx}",
                    "author": author,
                    "work": title,
                    "year":year,
                    "passage": passage
                })
            file_id += 1

    with open(OUTPUT_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["id", "author", "work", "year", "passage"], lineterminator="\n")
        writer.writeheader()
        writer.writerows(data)

    print(f"Output saved to: {OUTPUT_CSV}")

if __name__ == "__main__":
    main()
